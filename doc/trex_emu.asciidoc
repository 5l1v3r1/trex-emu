TRex EMU 
=========
:author: TRex team
:email: trex.tgen@gmail.com 
:revnumber:  0.1
:quotes.++:
:numbered:
:web_server_url: https://trex-tgn.cisco.com/trex
:local_web_server_url: csi-wiki-01:8181/trex
:github_emu_path: https://github.com/cisco-system-traffic-generator/trex-core/tree/master/scripts/emu
:github_stl_examples_path: https://github.com/cisco-system-traffic-generator/trex-core/tree/master/scripts/automation/trex_control_plane/interactive/trex/examples/emu
:toclevels: 6

include::trex_ga.asciidoc[]

// PDF version - image width variable
ifdef::backend-docbook[]
:p_width: 450
:p_width_1: 200
:p_width_1a: 100
:p_width_1b: 50
:p_width_1c: 150
:p_width_lge: 500
endif::backend-docbook[]

// HTML version - image width variable
ifdef::backend-xhtml11[]
:p_width: 800
:p_width_1: 400
:p_width_1a: 650
:p_width_1a: 400
:p_width_1b: 200
:p_width_lge: 900
endif::backend-xhtml11[]



== Audience

This document assumes basic knowledge of TRex, and assumes that TRex is installed and configured.
For information, see the link:trex_manual.html[manual], especially the material up to the link:trex_manual.html#_basic_usage[Basic Usage] section.

== Emulation support 

=== High level functionality

The objective is to implement client side L3 protocols i.e  arp,ipv6 nd,mld,igmp to simulate a scale of clients and servers. 
This project is not limited to client protocols, but it is a good start. The project provides a framework to write client protocols. 

The framework is fast enough for control protocol protocols and will work with TRex server. The very fast L7 application (on top of TCP/UDP) will run on TRex server.  One thread of trex-emu could achieve a high rate of client creation/teardown.
Plugins are self contained and could signal events to another plugin or to the framework using an event-bus (e.g. DHCP signal that it has a new IPv6 address). The framework has an event driven architecture, this way it could achive high scale, and provides to a protocol plugin infrastructure for example rpc,timers,packet parsers simulation and more. 


*The main properties*:: 

* Large new client creation/teardown.  ~3K/sec for one thread.
* Number of active client/namespace is limited only by the memory on the server. 
* Packet per second (PPS) in the range of 3-5 MPPS.
* Python 2.7/3.0 Client API expose json-rpc API.
* Interactive support - integrate with the TRex console.
* Modular design. Each plugin is self contained and can be tested by its own. 
* Support the following protocols 

[options="header",cols="1,2",width="60%"]
|=================
| Plug-in | Description
| arp     | RFC 826
| icmp    | RFC 777
| dhcpv4  | RFC 2131 client side
| igmp    | IGMP v3/v2/v1 RFC3376
| ipv6    | IPv6 ND, RFC 4443,RFC 4861,RFC 4862 and  MLD and MLDv2 RFC 3810 
| dhcpv6  | RFC 8415 client side
|=================

=== Interaction with TRex server

image::images/trex_arch.png[title="emu arch",align="left",width={p_width}, link="images/trex_arch.png"]

trex-emu can get commands (rpc via json-rpc) from Python client and send/receive packets via ZMQ channel that connected to TRex server (rx core). Packets from the network (from TRex server physical port) that match a filter (dynamic) are forwarded to the trex-emu process. Packets from emu process are packed into the zmq channel and sent directly to the TRex physical port.


=== Internal plugin architecture 

image::images/emu_arch.png[title="emu arch",align="left",width={p_width}, link="images/emu_arch.png"]

Each trex emulation process called `thread` could have a few `Namespaces`. 
`Namespace` could have a unique tuple key compose from {physical-port,dot1q,qinq}. The namespace key could be extended to tunnels in the future. 
Each `Client` can be associated with one `Namespace`. `protocol Plugin` could attach opaque object in each level (thread,namespace,client) and run a protocol logic e.g. dhcpv6 will be run in mainly in client object while mldv2 will run on namespace context. 

Different plugins and frameworks could communicate throw an event bus. A plugin could register on a topic and can send an event on a specific topic (e.g. dhcpv6 send change of source ipv6).

One special thing in this model is that `Clients` can share information on the same `Namespace` this way reduce the multicast  and broadcast packet duplication. 

image::images/emu_arp.png[title="emu arch",align="left",width={p_width}, link="images/emu_arp.png"]

The following figure shows that a shared ipv4 default gateway for many clients are resolved once and share with many clients. So arp broadcast packets does not need to be duplicated for each client. 
In this example if all the clients has the same default gateway 16.0.0.1, it will have only one instance in the arp cache table and each client will have a link to it. This is a scale in the number of clients can be achieved.  


=== EMU main objects 

* *Thread*: Includes a few namespace on different physical ports.  
* *Namespace*: A separate network entity that can include a number of clients. Each namespace has a unique  physical port, dot1q and qinq tuple key.
* *Namespace key tuple*: A unique tuple that create the key of the namespace 
* *Client*: Represents a separate network node in the namespace. For example a different laptop or server. Each node can have only one ipv4 source ip and a few ipv6 global and local ipv6 ip's.  
* *Plugin*: Implement a protocol logic or a tunnel logic. Could attach an opaque object to thread,namespace and client objects and use the framework API.

=== EMU Thread 

This object handles the following entities:

* RPC over json-rpc/zmq 
* Timer wheel 
* Event bus 
* ZMQ veth for tx/rx packets
* Parser to dispatch packets to plugins
* Manage vector of namespaces 
* Manage fast zero copy packet allocation (mbuf) - inspired by BSD 
* Counters engine 

=== EMU Namespace

[source,python]
----

type CNSCtx struct {
	ThreadCtx      *CThreadCtx
	PluginCtx      *PluginCtx
	DefClientPlugs *MapJsonPlugs 
}

type CNsInfo struct {
	Port          uint16    `json:"vport" validate:"required"`
	Tci           [2]uint16 `json:"tci"`
	Tpid          [2]uint16 `json:"tpid"`
	ActiveClients uint64    `json:"active_clients"`
	PlugNames     []string  `json:"plug_names"`
}


type CTunnelDataJson struct {
	Vport uint16    `json:"vport"`
	Tpid  [2]uint16 `json:"tpid"`
	Tci   [2]uint16 `json:"tci"`
	Plugins *MapJsonPlugs `json:"plugs"`
}

----

* Manage a vector of clients
* Each namespace should have a key of `CTunnelDataJson` and a vector of plugins string 
* Information per namespace has this object `CNsInfo` compose from tunnel key and active clients and plugin names 

=== EMU Client 

[source,python]
----

// CClientDg default GW
type CClientDg struct {
	IpdgResolved bool   `json:"resolve"` // bool in case it is resolved
	IpdgMac      MACKey `json:"rmac"`    // default
}

//CClientIpv6Nd information from learned from router
type CClientIpv6Nd struct {
	MTU        uint16  `json:"mtu"`   // MTU in L3 1500 by default
	DgMac      MACKey  `json:"dgmac"` // router dg
	PrefixIpv6 Ipv6Key `json:"prefix"`
	PrefixLen  uint8   `json:"prefix_len"`
	IPv6       Ipv6Key `json:"ipv6"`
}


type CClient struct {
	dlist  DList   // for adding into list
	Ns     *CNSCtx // pointer to a namespace
	Ipv4   Ipv4Key // source ipv4
	Maskv4 Ipv4Key // mask default 0xffffffff
	DgIpv4 Ipv4Key // default gateway for ipv4
	Mac    MACKey  // immutable over lifetime of client
	MTU    uint16  // MTU in L3 1500 by default

	DGW *CClientDg /* resolve by ARP */

	Ipv6Router *CClientIpv6Nd
	Ipv6DGW    *CClientDg /* resolve by ipv6 */
	Ipv6       Ipv6Key    // set the self ipv6 by user
	DgIpv6     Ipv6Key    // default gateway if provided would be in highest priority
	Dhcpv6     Ipv6Key    // the dhcpv6 ipv6, another ipv6 would be the one that was learned from the router

	Ipv6ForceDGW   bool /* true in case we want to enforce default gateway MAC */
	Ipv6ForcedgMac MACKey

	ForceDGW       bool /* true in case we want to enforce default gateway MAC */
	Ipv4ForcedgMac MACKey

	PluginCtx *PluginCtx
}

type CClientCmd struct {
	Mac    MACKey  `json:"mac" validate:"required"`  // the key mac addrees
	Ipv4   Ipv4Key `json:"ipv4"` // source ipv4 
	DgIpv4 Ipv4Key `json:"ipv4_dg"`  // default gateway 
	MTU    uint16  `json:"ipv4_mtu"` // ipv4 mtu 

	Ipv6   Ipv6Key `json:"ipv6"`  // source global ipv6 
	DgIpv6 Ipv6Key `json:"dg_ipv6"` // ipv6 default gateway 

	Ipv6ForceDGW   bool   `json:"ipv4_force_dg"` // force static default gateway 
	Ipv6ForcedgMac MACKey `json:"ipv4_force_mac"` // the mac of the forced default gateway 
	ForceDGW       bool   `json:"ipv6_force_dg"` // forced ipv4 default gateway 
	Ipv4ForcedgMac MACKey `json:"ipv6_force_mac"` // the MAC of the ipv4 forced default gateway 

	Plugins *MapJsonPlugs `json:"plugs"` // list of plugins
}

type CClientCmds struct {
	Clients []CClientCmd `json:"clients" validate:"required"`
}

type CClientInfo struct {
	Mac    MACKey  `json:"mac"`
	Ipv4   Ipv4Key `json:"ipv4"`
	DgIpv4 Ipv4Key `json:"ipv4_dg"`
	MTU    uint16  `json:"ipv4_mtu"`

	Ipv6Local Ipv6Key `json:"ipv6_local"`
	Ipv6Slaac Ipv6Key `json:"ipv6_slaac"`
	Ipv6      Ipv6Key `json:"ipv6"`
	DgIpv6    Ipv6Key `json:"dg_ipv6"`
	DhcpIpv6  Ipv6Key `json:"dhcp_ipv6"`

	Ipv6ForceDGW   bool   `json:"ipv4_force_dg"`
	Ipv6ForcedgMac MACKey `json:"ipv4_force_mac"`
	ForceDGW       bool   `json:"ipv6_force_dg"`
	Ipv4ForcedgMac MACKey `json:"ipv6_force_mac"`

	DGW *CClientDg `json:"dgw"`

	Ipv6Router *CClientIpv6Nd `json:"ipv6_router"`
	Ipv6DGW    *CClientDg     `json:"ipv6_dgw"`

	PlugNames []string `json:"plug_names"`
}
----

* Associated with one namespace (and namespace is associated with one thread).
* `CClientInfo` is the information retrieved for each client in RPC command.
** `CClientDg` is the ipv4 and ipv6 resolved default gateway using ipv6 nd,arp 
** `Ipv6Router` is the ipv6 router advertised information.  
* `CClientCmd` is the rpc json information to create a new client
* `CClientCmd.Plugins` is a vector of plugins for associating protocols plugins with a client/namespace example `[{'arp':{'enable':True}},{'icmp':{}},'dhcp':{'keep_alive':120}]`. In this example we enable `arp`,`icmp` and `dhcp` plugin for this client and we can provide a init configuration 
* One important limitation is that client does not have a routing table in the first version only a default gateway. It was done for simplicity because the out main objective is to verify a router/switch under test. It means that one client won't be able to communicate internally (i.g. ping) to another client on the same internal namespace. 

== Getting Started Tutorials

The tutorials in this section demonstrate basic use cases of trex-emu server. 

=== Tutorial: Load TRex server, One Client with ARP/ICMP plugin 

*Goal*:: 

Create *one* new client with one source ipv4 configuration and ping from the router. 
An ASR1K (Cisco IOS-XE) is used in the following tutorials and connected directly with physical port (without a switch). 


* ASR1K port (Ten1/0/0) 1.1.5.1/24 (255.255.255.0) 

* TRex port (0) 1.1.5.2/255.255.255.0

*Profile*:: 

link:{github_emu_path}/simple_emu.py[emu/simple_emu.py]

The profile is a way to create a database (tree) of namespaces and clients in Python and push this tree to the emu server via rpc commands. Let's look into the sections of a profile. 

[source,python]
----
..
class Prof1():
    def __init__(self):
        self.def_ns_plugs  = None   # <1> default plugin configuration for all ns derived from thread
        self.def_c_plugs  = None  #<2> default plugin configuration for each clients 

    def create_profile(self, ns_size, clients_size):
        ns_list = []

        # create different namespace each time
        vport, tci, tpid = 0, [0, 0], [0, 0]   ## the default vport, tci,tpid vector <3> setting the default vport,tpid
        ns_gen = NsGen(vport, tci, tpid, ns_size, p_inc = 1, tci_inc = 1)
        for vport, tci, tpid in ns_gen:
            ns = EMUNamespaceObj(vport  = vport,# create a namespace 
                                tci     = tci,
                                tpid    = tpid,
                                #plugs   = {}
                                def_c_plugs = self.def_c_plugs # default for all the client in this namespace 
                                )

            mac = '00:00:00:70:00:01'  # MAC start id
            ipv4 = '1.1.5.2'           # ipv4 start  
            dg = '1.1.5.1'             # default gateway 
            ipv6 = '1234::1000'        # ipv6 not used for now 
            c_gen = ClientGen(mac, ipv4, dg, ipv6, clients_size, mac_inc = 1, ipv4_inc = 1, ipv6_inc = 1)
            
            # create a different client each time
            for i, (mac, ipv4, dg, ipv6) in enumerate(c_gen):
                client = EMUClientObj(mac     = mac,
                                      ipv4    = ipv4,
                                      ipv4_dg = dg,
                                      ipv6    = ipv6,
                                       plugs   = {'arp': {},   # <4> this is the configuration that cvan overide the default 
                                                  #'igmp': {},
                                                  'icmp': {}
                                                 },
                                      )
                ns.add_clients(client)  ## adding the client 


            ns_list.append(ns)

        return EMUProfile(ns = ns_list, def_ns_plugs = self.def_ns_plugs)

    def get_profile(self, tuneables):
        # Argparse for tunables
        parser = argparse.ArgumentParser(description='Argparser for simple emu profile.')
        parser.add_argument('--ns', type = int, default = 1,
                    help='Number of namespaces to create')
        parser.add_argument('--clients', type = int, default = 15,
                    help='Number of clients to create in each namespace')

        args = parser.parse_args(tuneables)

        return self.create_profile(args.ns, args.clients)


def register():
    return Prof1()

----
<1> The default plugin configuration for all the namespaces attached to a thread, could be None. In case a namespace has a plugin configuration it will have a priority over the default. 
<2> The default plugin configuration for all the clients on the same namespace. In case a client has a plugin it will have a priority over the default.
<3> Setting the namespace tuple. In this example there is tree only on port zero and no dot1q/qinq
<4> Overide plugin configuration per client.

*Default plugin priority*:: 

.Namespace plugin vector
[options="header",cols="1,2,1",width="60%"]
|=================
| def_ns_plugs | EMUNamespaceObj.plugs | Results
| `{'arp: {'enable':true}}`  | None | `{'arp: {'enable':true}}` (taken from default)
| None   | `{'arp: {'enable':false}}` | `{'arp: {'enable':false}}` (per namespace has priority)
| `{'arp: {'enable':true}}`| `{'arp: {'enable':false}}` | `{'arp: {'enable':false}}` (per namespace has priority)
|=================


.Client plugin vector
[options="header",cols="1,2,1",width="60%"]
|=================
| EMUNamespaceObj.def_c_plugs | EMUClientObj.plugs | Results
| `{'arp: {'enable':true}}`  | None | `{'arp: {'enable':true}}` (taken from default)
| None   | `{'arp: {'enable':false}}` | `{'arp: {'enable':false}}` (per client has priority)
| `{'arp: {'enable':true}}`| `{'arp: {'enable':false}}` | `{'arp: {'enable':false}}` (per client has priority)
|=================

The ASR1K configuration 

[source,bash]
----
interface TenGigabitEthernet1/0/0
 mac-address 0000.0001.0000
 mtu 12500
 ip address 1.1.5.1 255.255.255.0
 load-interval 30
 arp timeout 70
----

The profile will create one clients with `1.1.5.2/24`. 

*Start TRex as a server*::   


[source,bash]
----
[bash]>sudo ./t-rex-64 -i -c 1 --software --emu 
----

the `--emu` CLI siwtch will load ZMQ channel to tx/rx packets and will tell the script to load the trex-emu server 

*Start the Console with EMU support*::   

[source,bash]
----
[bash]> ./trex-console  --emu

 
Using 'python3' as Python interpeter


Connecting to RPC server on s:4501                 [SUCCESS]


Connecting to publisher server on s:4500           [SUCCESS]


Acquiring ports [0, 1, 2, 3]:                [SUCCESS]


Server Info:

Server version:   v2.75 @ STL
Server mode:      Stateless
Server CPU:       2 x Intel(R) Xeon(R) CPU E5-2650 0 @ 2.00GHz
Ports count:      4 x 10Gbps @ 82599EB 10-Gigabit SFI/SFP+ Network Connection

Connecting to RPC server on s:4510               [SUCCESS]   <<< this is connected to the emu


Loading plugin: emu                            [SUCCESS]


-=TRex Console v3.0=-

trex>help

Emulation Commands:

emu_arp_cmd_query -            Arp cmd query command         
emu_arp_get_cfg -              Arp get configuration command 
emu_arp_set_cfg -              Arp set configuration command 
emu_arp_show_cache -           Arp show cache command        
emu_arp_show_counters -        Show arp counters data from arp table.
emu_dhcp_show_counters -       Show dhcp counters (per client).
emu_dhcpv6_show_counters -     Show dhcpv6 counters (per client).
emu_icmp_show_counters -       Show icmp counters (per client).
emu_igmp_add_mc -              IGMP add mc command           
emu_igmp_get_cfg -             IGMP get configuration command
emu_igmp_remove_mc -           IGMP remove mc command        
emu_igmp_set_cfg -             IGMP set configuration command
emu_igmp_show_counters -       Show IGMP counters data from igmp table.
emu_igmp_show_mc -             IGMP show mc command          
emu_ipv6_add_mld -             IPV6 add mld command          
emu_ipv6_get_cfg -             IPV6 get configuration command
emu_ipv6_remove_mld -          IPV6 remove mld command       
emu_ipv6_set_cfg -             IPV6 set configuration command
emu_ipv6_show_cache -          IPV6 show cache command       
emu_ipv6_show_counters -       Show IPV6 counters data from ipv6 table.
emu_ipv6_show_mld -            IPV6 show mld command         
emu_load_profile -             Load a given profile to emu server
emu_remove_profile -           Remove current profile from emu server
emu_show_all -                 Show all current namespaces & clients
emu_show_client_info -         Show client information       
emu_show_counters -            Show counters data from ctx according to given tables.
emu_show_mbuf -                Show mbuf usage in a table.   
emu_show_ns_info -             Show namespace information    
trex>

----

This command will load emu plugin automatically `--emu` and connect to the same server ip to zmq port 4510/rpc 
The emu commands will registers automatically  

*Load profile*::   

Loading profile from the console 

[source,bash]
----
    trex>portattr -a --prom on

    Applying attributes on port(s) [0, 1, 2, 3]:       [SUCCESS]

    trex>portattr -a --mult on

    Applying attributes on port(s) [0, 1, 2, 3]:       [SUCCESS]

    trex>portattr -a
    Port Status

        port       |          0           |          1            |   
    ----------------+----------------------+----------------------+--
    driver          |      net_ixgbe       |      net_ixgbe       |   
    description     |  82599EB 10-Gigabit  |  82599EB 10-Gigabit  |   
    link status     |          UP          |          UP          |   
    link speed      |       10 Gb/s        |       10 Gb/s        |   
    port status     |         IDLE         |         IDLE         |   
    promiscuous     |          on          |          on          |   
    multicast       |          on          |          on          | 
    flow ctrl       |         none         |         none         | 
    vxlan fs        |          -           |          -           | 
    --              |                      |                      | 
    layer mode      |       Ethernet       |       Ethernet       | 
    src IPv4        |          -           |          -           | 
    IPv6            |         off          |         off          | 
    src MAC         |  00:00:00:02:00:00   |  00:00:00:04:00:00   | 
    ---             |                      |                      | 
    Destination     |  00:00:00:01:00:00   |  00:00:00:03:00:00   | 
    ARP Resolution  |          -           |          -           | 
    ----            |                      |                      | 
    VLAN            |          -           |          -           | 
    -----           |                      |                      | 
    PCI Address     |     0000:03:00.0     |     0000:03:00.1     | 
    NUMA Node       |          0           |          0           | 
    RX Filter Mode  |    hardware match    |    hardware match    | 
    RX Queueing     |         off          |         off          | 
    Grat ARP        |         off          |         off          | 
    ------          |                      |                      | 



    trex>emu_load_profile -f emu/simple_emu.py -t --ns 1 --clients 1

    Converting file to profile                         [SUCCESS]

    Converting profile took: 24.81 [ms]

    Removing old emu profile                            [SUCCESS]


    Sending emu profile                                          
    [SUCCESS]                

    Sending profile took: 524.78 [ms]
    553.79 [ms]

    trex>emu_show_all 
    Namespace #1 Information

    Port | Vlan tags | Tpids | #Plugins | #Clients 
    -----+-----------+-------+----------+---------
    0   |     -      |   -    |    -     |    1     

    Clients Information

        MAC        |  IPv4   | DG-IPv4 | MTU  |    IPv6       |  
    ------------------+---------+---------+------+------------+-
    00:00:00:70:00:01 | 1.1.5.2 | 1.1.5.1 | 1500 | 1234::1000 |  

    560.78 [ms]

    trex>emu_show_client_info --mac 00:00:00:70:00:01 -p 0 --json
    {
        "plug_names": [
            "arp",
            "icmp"
        ],
        "dhcp_ipv6": "::",
        "mac": "00:00:00:70:00:01",
        "ipv4_force_dg": false,
        "ipv6_force_mac": "00:00:00:00:00:00",
        "dg_ipv6": "::",
        "ipv4_mtu": 1500,
        "ipv4_force_mac": "00:00:00:00:00:00",
        "ipv6_dgw": "None",
        "ipv6": "1234::1000",
        "ipv6_force_dg": false,
        "ipv4_dg": "1.1.5.1",
        "ipv6_local": "fe80::200:ff:fe70:1",
        "dgw": {
            "rmac": "00:00:00:00:00:00",
            "resolve": false
        },
        "ipv6_router": "None",
        "ipv4": "1.1.5.2",
        "ipv6_slaac": "::"
    }

    102.34 [ms]

    trex>emu_show_counters 
    Ctx Counters

    name     | value 
    ---------+------
    addNs    | 1     
    activeNs | 1     

    Mbuf-Pool Counters

        name       | value 
    ---------------+------
    mbufAlloc      | 2     
    mbufAllocCache | 10    
    mbufFreeCache  | 12    

    Timerw Counters

    name        | value  
    ------------+-------
    activeTimer | 2      
    ticks       | 146226 

    Mbuf-128 Counters

        name       | value 
    ---------------+------
    mbufAlloc      | 2     
    mbufAllocCache | 10    
    mbufFreeCache  | 12    

    Veth Counters

    name     | value 
    ---------+------
    TxPkts   | 12    
    TxBytes  | 504   
    TxBatch* | 11    

    248.72 [ms]

    trex>emu_show_mbuf           
    Mbuf Util

        Sizes:        | 128b  | 256b  | 512b  |  1k   |  2k   |  4k   | 9k 
    ------------------+-------+-------+-------+-------+-------+-------+---
    Allocations       |   2   |   0   |   0   |   0   |   0   |   0   | 0  
    Free              |   0   |   0   |   0   |   0   |   0   |   0   | 0  
    Cache Allocations |  11   |   0   |   0   |   0   |   0   |   0   | 0  
    Cache Free        |  13   |   0   |   0   |   0   |   0   |   0   | 0  
    Hit Rate          |  84%  |   0%  |   0%  |   0%  |   0%  |   0%  | 0% 
    Actives           |  26   |   0   |   0   |   0   |   0   |   0   | 0  

    123.68 [ms]

    trex>emu_show_ns_info -p 0
    Namespace Information

    Port | Vlan tags | Tpids | #Plugins | #Clients 
    -----+-----------+-------+----------+---------
    0    |     -     |   -   |    -     |    1     

    108.65 [ms]
----

*  Promiscuous and multicast should be turn on to forward the broadcast and multicast packets that relates to trex-emu. 
* `emu_load_profile` removes the old profile if exists and load the new profile using SDK API. 
* `emu_show_all` : shows all the clients 
* `emu_show_counters` : shows the framework counters for all engines 
* `emu_show_mbuf` : shows the framework packets buffers 
* `emu_show_client_info`: shows info per client
* `emu_show_ns_info`: shows info per namespace 

To show per plugin info use emu_xxx_yyy where xxx is the plugin name in this case let's try arp 

[source,bash]
----
  trex>emu_arp_show_counters -p 0
    Arp Counters

            name         | value 
    ---------------------+------
    timerEventIncomplete | 43    
    addIncomplete        | 1     
    pktTxArpQuery        | 54    
    pktTxGArp            | 1     
    tblActive            | 1     
    tblAdd               | 1     
    associateWithClient  | 1     

----

* `emu_arp_show_counters` works per namespace so you should provide port and tunnel (if exists). 
* The counters are global for all the clients on the same namespace as they share the arp cache table 

*Ping from the ASR1K*::   

[source,bash]
----
    csi-mcp-asr1k-40#show ip arp
    Protocol  Address          Age (min)  Hardware Addr   Type   Interface
    Internet  1.1.5.1                 -   0000.0001.0000  ARPA   TenGigabitEthernet1/0/0
    Internet  1.1.5.2                 0   0000.0070.0001  ARPA   TenGigabitEthernet1/0/0
    Internet  1.1.6.1                 -   0000.0003.0000  ARPA   TenGigabitEthernet1/1/0
    Internet  1.1.7.1                 -   0000.0005.0000  ARPA   TenGigabitEthernet1/2/0
    Internet  1.1.8.1                 -   0000.0007.0000  ARPA   TenGigabitEthernet1/3/0
    csi-mcp-asr1k-40#ping 1.1.5.2
    Type escape sequence to abort.
    Sending 5, 100-byte ICMP Echos to 1.1.5.2, timeout is 2 seconds:
    !!!!!
    Success rate is 100 percent (5/5), round-trip min/avg/max = 62/70/80 ms
    csi-mcp-asr1k-40
----

The router ideltify the client in the arp table and it is possible to ping to it from the router. 

Now you can try with 10,000 clients (but first you need to change the netmask to /16)

[source,bash]
----
trex>emu_load_profile -f emu/simple_emu.py -t --ns 1 --clients 10000
----

[NOTE]
=====================================================================
You will need to change the interface mask from 255.255.255.0 to 255.255.0.0
=====================================================================


=== Tutorial: IGMPv2/v3 

*Goal*:: Add a few clients and some multicast address

TRex support IGMPv2/v3 RFC3376 and could maintain (add/remove) scale of multicast ips. 

[source,python]
----
..
class Prof1():
    def __init__(self):
        self.def_ns_plugs  =  { 'igmp' : {'dmac':[0,0,0,0x70,0,1]]}}  #<1>
        self.def_c_plugs  = None 

    def create_profile(self, ns_size, clients_size):
        ns_list = []

        # create different namespace each time
        vport, tci, tpid = 0, [0, 0], [0, 0]   
        ns_gen = NsGen(vport, tci, tpid, ns_size, p_inc = 1, tci_inc = 1)
        for vport, tci, tpid in ns_gen:
            ns = EMUNamespaceObj(vport  = vport,# create a namespace 
                                tci     = tci,
                                tpid    = tpid,
                                def_c_plugs = self.def_c_plugs
                                )

            mac = '00:00:00:70:00:01'  # MAC start id
            ipv4 = '1.1.5.2'           # ipv4 start  
            dg = '1.1.5.1'             # default gateway 
            ipv6 = '1234::1000'        # ipv6 not used for now 
            c_gen = ClientGen(mac, ipv4, dg, ipv6, clients_size, 
                    mac_inc = 1, ipv4_inc = 1, ipv6_inc = 1)
            
            # create a different client each time
            for i, (mac, ipv4, dg, ipv6) in enumerate(c_gen):
                client = EMUClientObj(mac     = mac,
                                      ipv4    = ipv4,
                                      ipv4_dg = dg,
                                      ipv6    = ipv6,
                                       plugs   = {'arp': {},   
                                                  'igmp': {},
                                                  'icmp': {}
                                                 },
                                      )
                ns.add_clients(client)  ## adding the client 

            ns_list.append(ns)

        return EMUProfile(ns = ns_list, def_ns_plugs = self.def_ns_plugs)

def register():
    return Prof1()

----

* `self.def_ns_plugs  =  { 'igmp' : {'dmac':[0,0,0,0x70,0,1]]}}` is the init json for igmp plugin. The plugin works on the namespace domain (not client domain) and there is a need for *one* designator client. This client will represent the multicast groups for all the clients on the same namespace.
In this example we took the first client MAC (`00:00:00:70:00:01`). ``'dmac':[0,0,0,0x70,0,1]` is `00:00:00:70:00:01`. BTW the above could be done using Python API too. 
* `igmp` plugin should be enabled in the client plugs (`EMUClientObj`)

.Console 
[source,bash]
----
    trex>portattr -a --prom on                                          
    trex>emu_igmp_add_mc -p 0 --4 227.0.1.1 --4-count 10
    124.90 [ms]

    trex>emu_igmp_show_mc -p 0
    Current mc:

    227.0.1.1
    227.0.1.2
    227.0.1.3
    227.0.1.4
    227.0.1.5
    227.0.1.6
    227.0.1.7
    227.0.1.8
    227.0.1.9
    227.0.1.10
    227.0.1.11

    trex>emu_igmp_get_cfg -p 0
    Plugin "Igmp" Cfg:

    mtu  |       dmac        | version 
    -----+-------------------+--------
    1500 | 00:00:00:70:00:01 |    3    

----

* The first command add 227.0.1.1-227.1.11 multicast addrees 
* The igmp packets will be sent from client 00:00:00:70:00:01 
* The table could be seen using `emu_igmp_show_mc`


*ASR1K configuration*::   

.Config
[source,bash]
----
ip igmp limit 1000                      <<
ip multicast-routing distributed        <<

interface TenGigabitEthernet1/0/0
 mac-address 0000.0001.0000
 mtu 9050                            
 ip address 1.1.5.1 255.255.255.0
 ip pim sparse-dense-mode              <<
 ip igmp version 3                     <<
 ip igmp query-interval 10             <<    
 load-interval 30
----

Enable multicast routing and igmp

.Show the groups 
[source,bash]
----
>show ip igmp groups 
IGMP Connected Group Membership
Group Address    Interface                Uptime    Expires   Last Reporter 
227.0.1.1        TenGigabitEthernet1/0/0  00:00:28  00:00:29  1.1.5.2       
227.0.1.2        TenGigabitEthernet1/0/0  00:00:28  00:00:29  1.1.5.2       
227.0.1.3        TenGigabitEthernet1/0/0  00:00:28  00:00:29  1.1.5.2       
227.0.1.4        TenGigabitEthernet1/0/0  00:00:28  00:00:29  1.1.5.2       
227.0.1.5        TenGigabitEthernet1/0/0  00:00:28  00:00:29  1.1.5.2       
227.0.1.6        TenGigabitEthernet1/0/0  00:00:28  00:00:29  1.1.5.2       
227.0.1.7        TenGigabitEthernet1/0/0  00:00:28  00:00:29  1.1.5.2       
227.0.1.8        TenGigabitEthernet1/0/0  00:00:28  00:00:29  1.1.5.2       
227.0.1.9        TenGigabitEthernet1/0/0  00:00:28  00:00:29  1.1.5.2       
227.0.1.10       TenGigabitEthernet1/0/0  00:00:28  00:00:29  1.1.5.2       
227.0.1.11       TenGigabitEthernet1/0/0  00:00:28  00:00:29  1.1.5.2       
224.0.1.40       TenGigabitEthernet1/0/0  1w0d      00:00:22  1.1.5.1       
----

=== Tutorial: DHCPv4 

*Goal*:: Add clients that interact with DHCP server to get the IPv4/Default gateway 

[source,python]
----
..
class Prof1():
    def __init__(self):
        self.def_ns_plugs  =  { 'igmp' : {'dmac':[0,0,0,0x70,0,1]]}}  # <1>
        self.def_c_plugs  = None 
    def create_profile(self, ns_size, clients_size):
        ns_list = []

        # create different namespace each time
        vport, tci, tpid = 0, [0, 0], [0, 0]   
        ns_gen = NsGen(vport, tci, tpid, ns_size, p_inc = 1, tci_inc = 1)
        for vport, tci, tpid in ns_gen:
            ns = EMUNamespaceObj(vport  = vport,# create a namespace 
                                tci     = tci,
                                tpid    = tpid,
                                def_c_plugs = self.def_c_plugs
                                )

            mac = '00:00:00:70:00:01'  # MAC start id
            ipv4 = '0.0.0.0'           # ipv4 start  
            dg = '0.0.0.0'             # default gateway 
            ipv6 = '1234::1000'        # ipv6 not used for now 
            c_gen = ClientGen(mac, ipv4, dg, ipv6, clients_size, mac_inc = 1, ipv4_inc = 0, ipv6_inc = 1)
            
            # create a different client each time
            for i, (mac, ipv4, dg, ipv6) in enumerate(c_gen):
                client = EMUClientObj(mac     = mac,
                                      ipv4    = ipv4,
                                      ipv4_dg = dg,
                                      ipv6    = ipv6,
                                       plugs   = {'arp': {},   
                                                  'igmp': {},
                                                  'icmp': {},
                                                  'dhcp': {},
                                                 },
                                      )
                ns.add_clients(client)  ## adding the client 


            ns_list.append(ns)

        return EMUProfile(ns = ns_list, def_ns_plugs = self.def_ns_plugs)

def register():
    return Prof1()

----

* Add 'dhcp' to the client plugin  
* Change ipv4/dg to 0.0.0.0  
* change `ipv4_inc` to zero as DHCP will change the IP

Now each client will request the IPv4/Default gateway from the DHCP server and signal to arp/icmp with the right new IPv4 source addrees and default gateway. 

*ASR1K configuration*::   

.Config
[source,bash]
----
ip dhcp pool 1
 network 1.1.5.0 255.255.255.0
 domain-name cisco.com
 dns-server 172.16.1.103 172.16.2.10 
 lease 30 
----


[source,bash]
----
    trex>emu_load_profile -f emu/simple_dhcp.py -t --ns 1 --clients 10

    Converting file to profile                                   10
    [SUCCESS]

    Converting profile took: 34.62 [ms]

    Removing old emu profile                                     
    [SUCCESS]                


    Sending emu profile                                          
    [SUCCESS]                

    Sending profile took: 2.13 [sec]
    2.17 [sec]

    trex>emu_show_all 
    Namespace #1 Information

    Port | Vlan tags | Tpids | #Plugins | #Clients 
    -----+-----------+-------+----------+---------
    0   |     -     |   -   |    -     |    10    

    Clients Information

        MAC        |   IPv4   | DG-IPv4 | MTU  |        IPv6             
    ------------------+----------+---------+------+---------------------+
    00:00:00:70:00:01 | 1.1.5.22 | 1.1.5.1 | 1500 | fe80::200:ff:fe70:1 |
    00:00:00:70:00:02 | 1.1.5.72 | 1.1.5.1 | 1500 | fe80::200:ff:fe70:2 |
    00:00:00:70:00:03 | 1.1.5.73 | 1.1.5.1 | 1500 | fe80::200:ff:fe70:3 |
    00:00:00:70:00:04 | 1.1.5.70 | 1.1.5.1 | 1500 | fe80::200:ff:fe70:4 |
    00:00:00:70:00:05 | 1.1.5.71 | 1.1.5.1 | 1500 | fe80::200:ff:fe70:5 |
    00:00:00:70:00:06 | 1.1.5.68 | 1.1.5.1 | 1500 | fe80::200:ff:fe70:6 |
    00:00:00:70:00:07 | 1.1.5.69 | 1.1.5.1 | 1500 | fe80::200:ff:fe70:7 |
    00:00:00:70:00:08 | 1.1.5.66 | 1.1.5.1 | 1500 | fe80::200:ff:fe70:8 |
    00:00:00:70:00:09 | 1.1.5.67 | 1.1.5.1 | 1500 | fe80::200:ff:fe70:9 |
    00:00:00:70:00:0a | 1.1.5.89 | 1.1.5.1 | 1500 | fe80::200:ff:fe70:a |

    990.49 [ms]

    trex>
    trex>emu_dhcp_show_counters -p 0 --mac 00:00:00:70:00:01
    Dhcp Counters

        name      | value 
    --------------+------
    pktTxDiscover | 1     
    pktRxOffer    | 1     
    pktTxRequest  | 1     
    pktRxAck      | 1     
    pktRxNotify   | 1     

    229.34 [ms]
----


* dhcp plugin works per client, so the MAC should be provided to get the counters 


.Show
[source,bash]
----
    #show ip  dhcp server statistics 
    Memory usage         65910
    Address pools        1
    Database agents      0
    Automatic bindings   100
    Manual bindings      0
    Expired bindings     0
    Malformed messages   0
    Secure arp entries   0
    Renew messages       0
    Workspace timeouts   0
    Static routes        0
    Relay bindings       0
    Relay bindings active        0
    Relay bindings terminated    0
    Relay bindings selecting     0

    Message              Received
    BOOTREQUEST          0
    DHCPDISCOVER         302272
    DHCPREQUEST          211
    DHCPDECLINE          0
    DHCPRELEASE          125
    DHCPINFORM           0
    DHCPVENDOR           0
    BOOTREPLY            0
    DHCPOFFER            0
    DHCPACK              0
    DHCPNAK              0

    Message              Sent
    BOOTREPLY            0
    DHCPOFFER            211
    DHCPACK              211
    DHCPNAK              0

    Message              Forwarded
    BOOTREQUEST          0
    DHCPDISCOVER         0
    DHCPREQUEST          0
    DHCPDECLINE          0
    DHCPRELEASE          0
    DHCPINFORM           0
    DHCPVENDOR           0
    BOOTREPLY            0
    DHCPOFFER            0
    DHCPACK              0
    DHCPNAK              0
            
    DHCP-DPM Statistics
    Offer notifications sent        0
    Offer callbacks received        0
    Classname requests sent         0
    Classname callbacks received    0
            
----

=== Tutorial: IPv6/MLDv2/DHCPV6

*Goal*:: Add clients with static IPv6 and global SLAAC ipv6 address and dhcpv6 

IPv6 client side are based on the folowing RFC
 
* RFC 4443
* RFC 4861
* RFC 4862 
* MLD1/MLDv2 RFC 3810. 

It was written from scratch so it might have some issues. 

[source,python]
----
..
class Prof1():
    def __init__(self):
        self.def_ns_plugs  =  { 'igmp' : {'dmac':[0,0,0,0x70,0,1]]},
                                'dhcpv6' : {'dmac':[0,0,0,0x70,0,1]]}}  # <1>
        self.def_c_plugs  = None 
    def create_profile(self, ns_size, clients_size):
        ns_list = []

        # create different namespace each time
        vport, tci, tpid = 0, [0, 0], [0, 0]   
        ns_gen = NsGen(vport, tci, tpid, ns_size, p_inc = 1, tci_inc = 1)
        for vport, tci, tpid in ns_gen:
            ns = EMUNamespaceObj(vport  = vport,# create a namespace 
                                tci     = tci,
                                tpid    = tpid,
                                def_c_plugs = self.def_c_plugs
                                )

            mac = '00:00:00:70:00:01'  # MAC start id
            ipv4 = '0.0.0.0'           # ipv4 start  
            dg = '0.0.0.0'             # default gateway 
            ipv6 = '2001:DB8:1::2'         # ipv6 not used for now 
            c_gen = ClientGen(mac, ipv4, dg, ipv6, clients_size, 
                              mac_inc = 1, ipv4_inc = 0, ipv6_inc = 1)
            
            # create a different client each time
            for i, (mac, ipv4, dg, ipv6) in enumerate(c_gen):
                client = EMUClientObj(mac     = mac,
                                      ipv4    = ipv4,
                                      ipv4_dg = dg,
                                      ipv6    = ipv6,
                                       plugs   = {'ipv6': {},   
                                                  'dhcpv6': {},
                                                 },
                                      )
                ns.add_clients(client)  ## adding the client 


            ns_list.append(ns)

        return EMUProfile(ns = ns_list, def_ns_plugs = self.def_ns_plugs)

def register():
    return Prof1()

----

* `def_ns_plugs` add `'dhcpv6' : {'dmac':[0,0,0,0x70,0,1]]}` this will add the first client as a designator for the mldv2 
* Client plugins add `ipv6` and `dhcpv6`


*ASR1K configuration*::   

.ASR1K Config
[source,bash]
----
ipv6 nd cache interface-limit 1000
ipv6 unicast-routing
ipv6 dhcp pool p1
 address prefix 2001:DB8:1201::/64
 dns-server 2001:DB8:3000:3000::42
 domain-name cisco.com
!         
ipv6 multicast-routing
ipv6 multicast rpf use-bgp
!         
interface TenGigabitEthernet1/0/0
 mac-address 0000.0001.0000
 mtu 9050 
 ip address 1.1.5.1 255.255.255.0
 load-interval 30
 ipv6 address 2001:DB8:1::1/64
 ipv6 address 2001:DB8:4:2222::1/64
 ipv6 enable
 ipv6 dhcp server p1
 ipv6 mld query-timeout 10
 ipv6 mld query-interval 5
!         
----

.Console
[source,bash]
----
    trex>emu_load_profile -f emu/simple_dhcp.py -t --ns 1 --clients 10

    trex>emu_show_client_info -p 0 --mac 00:00:00:70:00:01 --json
    {
        "ipv6_force_mac": "00:00:00:00:00:00",
        "ipv6_dgw": "None",
        "ipv4_force_dg": false,
        "plug_names": [
            "dhcpv6",
            "ipv6"
        ],
        "mac": "00:00:00:70:00:01",
        "ipv4_force_mac": "00:00:00:00:00:00",
        "ipv6_local": "fe80::200:ff:fe70:1",
        "ipv6_force_dg": false,
        "ipv6_router": {
            "mtu": 9050,
            "prefix": "2001:db8:1::",
            "prefix_len": 64,
            "dgmac": "00:00:00:01:00:00",
            "ipv6": "fe80::200:ff:fe01:0"
        },
        "ipv4": "0.0.0.0",
        "dg_ipv6": "::",
        "ipv4_dg": "0.0.0.0",
        "ipv6": "2001:db8:1::2",
        "ipv4_mtu": 1500,
        "dgw": "None",
        "ipv6_slaac": "2001:db8:1:0:200:ff:fe70:1",
        "dhcp_ipv6": "2001:DB8:1201::1"
    }
    94.06 [ms]

    trex>emu_show_all 
    Namespace #1 Information

    Port | Vlan tags | Tpids | #Plugins | #Clients 
    -----+-----------+-------+----------+---------
    0   |     -     |   -   |    -     |    10    

    Clients Information

        MAC        | MTU  |     IPv6      | DHCP DG-IPv6 |     IPv6 Local            |         
    ------------------+------+---------------+--------------+---------------------+---
    00:00:00:70:00:01 | 1500 | 2001:db8:1::2 | 2001:DB8:1201::1| fe80::200:ff:fe70:1 |
    00:00:00:70:00:02 | 1500 | 2001:db8:1::3 | 2001:DB8:1201::2| fe80::200:ff:fe70:2 |
    00:00:00:70:00:03 | 1500 | 2001:db8:1::4 | 2001:DB8:1201::3| fe80::200:ff:fe70:3 |
    00:00:00:70:00:04 | 1500 | 2001:db8:1::5 | 2001:DB8:1201::4| fe80::200:ff:fe70:4 |
    00:00:00:70:00:05 | 1500 | 2001:db8:1::6 | 2001:DB8:1201::5| fe80::200:ff:fe70:5 |
    00:00:00:70:00:06 | 1500 | 2001:db8:1::7 | 2001:DB8:1201::6| fe80::200:ff:fe70:6 |
    00:00:00:70:00:07 | 1500 | 2001:db8:1::8 | 2001:DB8:1201::7| fe80::200:ff:fe70:7 |
    00:00:00:70:00:08 | 1500 | 2001:db8:1::9 | 2001:DB8:1201::8| fe80::200:ff:fe70:8 |
    00:00:00:70:00:09 | 1500 | 2001:db8:1::a | 2001:DB8:1201::9| fe80::200:ff:fe70:9 |
    00:00:00:70:00:0a | 1500 | 2001:db8:1::b | 2001:DB8:1201::10| fe80::200:ff:fe70:a 

    1.31 [sec]

    trex>emu_dhcpv6_show_counters -p 0 --mac 00:00:00:70:00:01        
    Dhcpv6 Counters

        name      | value 
    --------------+------
    pktTxDiscover | 1     
    pktRxOffer    | 1     
    pktTxRequest  | 1     
    pktRxAck      | 1     
    pktRxNotify   | 1     

trex>emu_ipv6_show_cache -p 0
Ipv6 Cache

state |        mac        | refc | resolve |        ipv6         
------+-------------------+------+---------+--------------------
 16   | 00:00:00:01:00:00 |  0   |  True   | fe80::200:ff:fe01:0 


359.88 [ms]

trex>emu_ipv6_show_mld -p 0  
Current mld:

ff02::1
ff02::1:ff70:9
ff02::1:ff00:a
ff02::1:ff70:5
ff02::1:ff00:6
ff02::1:ff70:7
ff02::1:ff00:8
ff02::1:ff70:1
ff02::1:ff00:2
ff02::1:ff70:8
ff02::1:ff00:9
ff02::1:ff70:2
ff02::1:ff00:3
ff02::1:ff70:3
ff02::1:ff00:4
ff02::1:ff70:6
ff02::1:ff00:7
ff02::1:ff70:4
ff02::1:ff00:5
ff02::1:ff70:a
ff02::1:ff00:b
ff02::1:ffa7:37e
ff02::1:ffb0:a3cc
ff02::1:ff38:6001
ff02::1:ff53:5155
ff02::1:ff83:2c7c
ff02::1:ff20:5fbe
ff02::1:ffd3:8103
ff02::1:ff58:6891
ff02::1:ffd5:2abf
ff02::1:ff6b:eb42

225.61 [ms]

----



.ASR1K Show
[source,bash]
----

>show ipv6 dhcp statistics 
Messages received                152918
Messages sent                    142604
Messages discarded               10314
Messages could not be sent       0

Messages                         Received
SOLICIT                          141422
REQUEST                          761
RELEASE                          10735

Messages                         Sent
ADVERTISE                        141422
REPLY                            1182

Messages discarded due to:
Reason                                                   Count
Invalid options                                          10314

>show ipv6 neighbors 
IPv6 Address                              Age Link-layer Addr State Interface
2001:DB8:1::2                               0 0000.0070.0001  STALE Te1/0/0
2001:DB8:1::3                               0 0000.0070.0002  STALE Te1/0/0
2001:DB8:1::4                               0 0000.0070.0003  STALE Te1/0/0
2001:DB8:1::5                               0 0000.0070.0004  STALE Te1/0/0
2001:DB8:1::6                               0 0000.0070.0005  STALE Te1/0/0
2001:DB8:1::7                               0 0000.0070.0006  STALE Te1/0/0
2001:DB8:1::8                               0 0000.0070.0007  STALE Te1/0/0
2001:DB8:1::9                               0 0000.0070.0008  STALE Te1/0/0
2001:DB8:1::A                               0 0000.0070.0009  STALE Te1/0/0
2001:DB8:1::B                               0 0000.0070.000a  STALE Te1/0/0
2001:DB8:1:0:200:FF:FE70:1                  0 0000.0070.0001  STALE Te1/0/0
2001:DB8:1:0:200:FF:FE70:2                  0 0000.0070.0002  STALE Te1/0/0
2001:DB8:1:0:200:FF:FE70:3                  0 0000.0070.0003  STALE Te1/0/0
2001:DB8:1:0:200:FF:FE70:4                  0 0000.0070.0004  STALE Te1/0/0
2001:DB8:1:0:200:FF:FE70:5                  0 0000.0070.0005  STALE Te1/0/0
2001:DB8:1:0:200:FF:FE70:6                  0 0000.0070.0006  STALE Te1/0/0
2001:DB8:1:0:200:FF:FE70:7                  0 0000.0070.0007  STALE Te1/0/0
2001:DB8:1:0:200:FF:FE70:8                  0 0000.0070.0008  STALE Te1/0/0
2001:DB8:1:0:200:FF:FE70:9                  0 0000.0070.0009  STALE Te1/0/0
2001:DB8:1:0:200:FF:FE70:A                  0 0000.0070.000a  STALE Te1/0/0
2001:DB8:1201:0:1058:160:2D6B:EB42          0 0000.0070.000a  STALE Te1/0/0
2001:DB8:1201:0:4097:A4E8:72A7:37E          0 0000.0070.0009  STALE Te1/0/0
2001:DB8:1201:0:6CCE:E021:7753:5155         0 0000.0070.0001  STALE Te1/0/0
2001:DB8:1201:0:6DF5:1CCC:D7D5:2ABF         0 0000.0070.0004  STALE Te1/0/0
2001:DB8:1201:0:8559:F959:E258:6891         0 0000.0070.0006  STALE Te1/0/0
2001:DB8:1201:0:89E5:B4B3:F238:6001         0 0000.0070.0007  STALE Te1/0/0
2001:DB8:1201:0:9DA9:7803:E3B0:A3CC         0 0000.0070.0005  STALE Te1/0/0
2001:DB8:1201:0:C4E7:2D31:8683:2C7C         0 0000.0070.0008  STALE Te1/0/0
2001:DB8:1201:0:DDEE:C998:F120:5FBE         0 0000.0070.0002  STALE Te1/0/0
2001:DB8:1201:0:F525:CCA0:79D3:8103         0 0000.0070.0003  STALE Te1/0/0
FE80::200:FF:FE70:1                         0 0000.0070.0001  STALE Te1/0/0
FE80::200:FF:FE70:2                         0 0000.0070.0002  STALE Te1/0/0
FE80::200:FF:FE70:3                         0 0000.0070.0003  STALE Te1/0/0
FE80::200:FF:FE70:4                         0 0000.0070.0004  STALE Te1/0/0
FE80::200:FF:FE70:5                         0 0000.0070.0005  REACH Te1/0/0
FE80::200:FF:FE70:6                         0 0000.0070.0006  STALE Te1/0/0
FE80::200:FF:FE70:7                         0 0000.0070.0007  STALE Te1/0/0
FE80::200:FF:FE70:8                         0 0000.0070.0008  STALE Te1/0/0
FE80::200:FF:FE70:9                         0 0000.0070.0009  REACH Te1/0/0
FE80::200:FF:FE70:A                         0 0000.0070.000a  STALE Te1/0/0

>show ipv6 mld groups 
MLD Connected Group Membership
Group Address                           Interface                            
FF05::1:3                               Te1/0/0                              


>show ipv6 mld traffic 
MLD Traffic Counters
Elapsed time since counters cleared: 7w0d

                              Received     Sent
Valid MLD Packets               19156       129235    
Queries                         0           76308     
Reports                         19156       52927     
Leaves                          0           0         
Mtrace packets                  0           0         

Errors:
Malformed Packets                           0         
Martian source                              0         
Non link-local source                       0         
Hop limit is not equal to 1                 0         
            
>ping ipv6 2001:DB8:1::2                               
Type escape sequence to abort.
Sending 5, 100-byte ICMP Echos to 2001:DB8:1::2, timeout is 2 seconds:
!!!!!
Success rate is 100 percent (5/5), round-trip min/avg/max = 101/108/117 ms
----


* Every client advertise all the global ipv6 ip using ns packet and its own local-ipv6. 
* MLDv2 is used (mldv1 is supported too but less effient) to publish the solicited multicast addrees for each IPv6 global addrees.  
* DHCPv6 does as not have default gateway, only the Slaac can be user or explict addrees 


=== Python API 

.API example 
[source,python]
----

    c = EMUClient(server=EMU_SERVER,
                    sync_port=4510,
                    verbose_level= "error",
                    logger=None,
                    sync_timeout=None)

    # load profile
    parser = argparse.ArgumentParser(
            description='Simple script to run EMU profile.')
    parser.add_argument("-f", "--file", required = True, dest="file", 
                        help="Python file with a valid EMU profile.")
    args = parser.parse_args()

    c.connect()

    print("loading profile from: %s" % args.file)

    # start the emu profile
    c.load_profile(filename = args.file, max_rate = 2048, tunables = '')

    # print tables of namespaces and clients
    c.print_all_ns_clients(max_ns_show = 1, max_c_show = 10)

----


This script assume there is a trex-emu server running on port 4510. It connects and load a profile with tunables and then print all the clients. 

For all the API plugin details and more examples have a look in the Python API doc. 


=== Tutorial: Debug tools

* traces could be taken from TRex server in the usual way 
* To debug trex-emu packet traces `trex-emu  -m | tee /tmp/a.pcap`. It will create a file with k12 packet format 
* To debug the rpc channel use  `trex-emu  -v`



== FAQ 

=== I want to add more protocols how could I do it? 

The framework is written in golang. I would start with icmp plugin as it is the simplest example. 

=== Is it possible to sync ASTF/STL clients addrees with trex-emu ?

I would like to create 1000 clients using trex-emu and use the same dhcp/dhcpv6 address with ASTF/STL profile. 

For STL you can use Field engine but it is limited with side. We would create a indirect table that could be fill with the information from trex-emu. 

for ASTF there is no support and the MAC,IPv4,IPv6 should be static. 

=== Why did you write all the RFC from scratch? 

Wouldn't it be easier to use a user space tcp/ip stack for example linux or freebsd? The answer is that for traffic generation the split betwean kernel and user space was a big challenge to solve our scale objective (e.g. high rate of creation of clients) and cohesiveness betwean protocols. For example DHCP and 802.1x is a user space while arp/ipv6 nd is kernel. Another example IGMP is a user space socket option. To control many clients imp there is a need to create many processes that open socket to Linux namespace and this is not scalable.

The is a big penalty in this method. There is a need to write from scratch the protocols, but there are some pluses:

1. The scale is very high 
2. There is no separation betwean kernel/user-space
3. Can manipulate the code for traffic generation exception 
4. It's fun to write in go long  


=== Why golang and not Python or c++

First, golang was an experiment. You can see from the code that this is the first time the developers write in golang. However, it is hard now to go back to c++. 

Why not Python?

Python has a few drawbacks for this project:

1. Speed: x50 slower than golang 
2. Dynamic language: hard to tag and control a large code base 



Why not C++?

1. Speed was not a concern and trex-core became slow to build 
2. We wanted a scalable and more modular design as the scale in trex-emu is more from a functionality point of view (more protocol support, development speed etc) and not PPS.

What is missing in golang:

1. Generic, interface{} is not enough  


=== I need to write a tunnel plugin like ppoe/gre can I  do it?

You can but we should add a support in the framework first


=== My plugin requires TCP/TLS/QUIC socket 


Not supported yet. The API would be event driver API. 


